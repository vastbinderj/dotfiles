
.TH "GCLOUD_DATAPROC_JOBS_SUBMIT" 1



.SH "NAME"
.HP
gcloud dataproc jobs submit \- submit Google Cloud Dataproc jobs to execute on a cluster



.SH "SYNOPSIS"
.HP
\f5gcloud dataproc jobs submit\fR \fICOMMAND\fR [\fB\-\-async\fR] [\fB\-\-bucket\fR=\fIBUCKET\fR] [\fIGLOBAL\-FLAG\ ...\fR]



.SH "DESCRIPTION"

Submit Google Cloud Dataproc jobs to execute on a cluster.



.SH "FLAGS"

.RS 2m
.TP 2m
\fB\-\-async\fR
Does not wait for the job to run.

.TP 2m
\fB\-\-bucket\fR=\fIBUCKET\fR
The Cloud Storage bucket to stage files in. Defaults to the cluster's configured
bucket.


.RE
.sp

.SH "GLOBAL FLAGS"

Run \fB$ gcloud help\fR for a description of flags available to all commands.



.SH "COMMANDS"

\f5\fICOMMAND\fR\fR is one of the following:

.RS 2m
.TP 2m
\fBhadoop\fR
Submit a Hadoop job to a cluster.

.TP 2m
\fBhive\fR
Submit a Hive job to a cluster.

.TP 2m
\fBpig\fR
Submit a Pig job to a cluster.

.TP 2m
\fBpyspark\fR
Submit a PySpark job to a cluster.

.TP 2m
\fBspark\fR
Submit a Spark job to a cluster.

.TP 2m
\fBspark\-sql\fR
Submit a Spark SQL job to a cluster.


.RE
.sp

.SH "EXAMPLES"

To submit a Hadoop MapReduce job, run:

.RS 2m
$ gcloud dataproc jobs submit hadoop \-\-cluster my_cluster \e
    \-\-jar my_jar.jar arg1 arg2
.RE

To submit a Spark Scala or Java job, run:

.RS 2m
$ gcloud dataproc jobs submit spark \-\-cluster my_cluster \e
    \-\-jar my_jar.jar arg1 arg2
.RE

To submit a PySpark job, run:

.RS 2m
$ gcloud dataproc jobs submit pyspark \-\-cluster my_cluster \e
    my_script.py arg1 arg2
.RE

To submit a Spark SQL job, run:

.RS 2m
$ gcloud dataproc jobs submit spark\-sql \-\-cluster my_cluster \e
    \-\-file my_queries.q
.RE

To submit a Pig job, run:

.RS 2m
$ gcloud dataproc jobs submit pig \-\-cluster my_cluster \e
    \-\-file my_script.pig
.RE

To submit a Hive job, run:

.RS 2m
$ gcloud dataproc jobs submit hive \-\-cluster my_cluster \e
    \-\-file my_queries.q
.RE
